{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "547c762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import MSELoss\n",
    "from torch.nn.functional import mse_loss\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob\n",
    "from compute_distance import compute_distance\n",
    "from scipy.spatial import cKDTree\n",
    "from shapely.geometry import Point, Polygon, LineString\n",
    "from shapely.ops import unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_path = 'models/'\n",
    "model = \"\"\n",
    "data_path = 'data/unscaled_p/'\n",
    "data_pattern = 'TrP4_*_10.csv'\n",
    "\n",
    "num_epochs = 500\n",
    "batch_size = 2000\n",
    "\n",
    "loss_fn = mse_loss\n",
    "\n",
    "h_n = 64\n",
    "input_n = 4\n",
    "n_layers = 8\n",
    "\n",
    "ds = 0.4\n",
    "dp = 0.1\n",
    "\n",
    "lr = [1e-3, 1e-3, 2e-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5e7f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f5f0016d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "# General PINN architecture for u, v, or p\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_dim=4, output_dim=1, hidden_dim=64, num_layers=8):\n",
    "        super(PINN, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        # Input layer\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(Swish())\n",
    "\n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 1):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(Swish())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6b6f207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_models():\n",
    "    net_u = PINN(input_dim=input_n, output_dim=1, hidden_dim=h_n, num_layers=n_layers).to(device)\n",
    "    net_v = PINN(input_dim=input_n, output_dim=1, hidden_dim=h_n, num_layers=n_layers).to(device)\n",
    "    net_p = PINN(input_dim=input_n, output_dim=1, hidden_dim=h_n, num_layers=n_layers).to(device)\n",
    "\n",
    "    def init_xavier(model):\n",
    "        for m in model.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)  # or small constant like 1e-3\n",
    "\n",
    "    net_u.apply(init_xavier)\n",
    "    net_v.apply(init_xavier)\n",
    "    net_p.apply(init_xavier)\n",
    "\n",
    "    optimizer_u = optim.Adam(net_u.parameters(), lr=lr[0])\n",
    "    optimizer_v = optim.Adam(net_v.parameters(), lr=lr[1])\n",
    "    optimizer_p = optim.Adam(net_p.parameters(), lr=lr[2])\n",
    "\n",
    "    scheduler_u = optim.lr_scheduler.ReduceLROnPlateau(optimizer_u, mode='min', factor=0.5, patience=50, min_lr=1e-6)\n",
    "    scheduler_v = optim.lr_scheduler.ReduceLROnPlateau(optimizer_v, mode='min', factor=0.5, patience=50, min_lr=1e-6)\n",
    "    scheduler_p = optim.lr_scheduler.ReduceLROnPlateau(optimizer_p, mode='min', factor=0.5, patience=50, min_lr=1e-6)\n",
    "\n",
    "    if os.path.exists(f\"{weights_path}/{model}_u.pth\"):\n",
    "        net_u.load_state_dict(torch.load(f\"{weights_path}/{model}_u.pth\"))\n",
    "    if os.path.exists(f\"{weights_path}/{model}_v.pth\"):\n",
    "        net_v.load_state_dict(torch.load(f\"{weights_path}/{model}_v.pth\"))\n",
    "    if os.path.exists(f\"{weights_path}/{model}_p.pth\"):\n",
    "        net_p.load_state_dict(torch.load(f\"{weights_path}/{model}_p.pth\"))\n",
    "\n",
    "    return net_u, net_v, net_p, optimizer_u, optimizer_v, optimizer_p, scheduler_u, scheduler_v, scheduler_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf357afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLD_Dataset(Dataset):\n",
    "    def __init__(self, data_path, data_pattern):\n",
    "        self.files = sorted(glob.glob(os.path.join(data_path, data_pattern)))\n",
    "        self.data = []\n",
    "\n",
    "        for file in self.files:\n",
    "            df = pd.read_csv(file)\n",
    "\n",
    "            inputs = df[['x', 'y', 'd', 'N']].values\n",
    "            targets = df[['u', 'v', 'p']].values\n",
    "            self.data.append((inputs, targets))\n",
    "\n",
    "        self.inputs = torch.tensor(np.vstack([d[0] for d in self.data]), dtype=torch.float32)\n",
    "        self.targets = torch.tensor(np.vstack([d[1] for d in self.data]), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.inputs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.inputs[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c0519054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(inputs, targets, net_u, net_v, net_p, loss_fn, epoch, rho=1.0, nu=0.01, ds=0.4, dp = 0.1):\n",
    "    x, y, d, n = inputs[:, 0], inputs[:, 1], inputs[:, 2], inputs[:, 3]\n",
    "\n",
    "    x.requires_grad_()\n",
    "    y.requires_grad_()\n",
    "    d.requires_grad_()\n",
    "    n.requires_grad_()\n",
    "\n",
    "    input_tensor = torch.stack((x, y, d, n), dim=1)\n",
    "\n",
    "    u_pred = net_u(input_tensor).squeeze(1)\n",
    "    v_pred = net_v(input_tensor).squeeze(1)\n",
    "    p_pred = net_p(input_tensor).squeeze(1)\n",
    "\n",
    "    distances = compute_distance(x, y, d, n, ds)\n",
    "\n",
    "    ####\n",
    "    # u_hard = u_pred\n",
    "    # v_hard = v_pred\n",
    "    # p_hard = p_pred\n",
    "\n",
    "    u_hard = u_pred * distances\n",
    "    v_hard = v_pred * distances\n",
    "\n",
    "    xStart = 0\n",
    "    xEnd = ds\n",
    "\n",
    "    p_par = ((xEnd - x) / (xEnd - xStart) * dp) + ((x - xStart) * (xEnd - xStart) * 0.0)\n",
    "    Dp = (x - xStart) * (xEnd - x)\n",
    "    p_hard = p_par + Dp * p_pred\n",
    "\n",
    "    u_x = torch.autograd.grad(u_hard, x, grad_outputs=torch.ones_like(u_hard), create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "    u_y = torch.autograd.grad(u_hard, y, grad_outputs=torch.ones_like(u_hard), create_graph=True)[0]\n",
    "    u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=True)[0]\n",
    "\n",
    "    v_x = torch.autograd.grad(v_hard, x, grad_outputs=torch.ones_like(v_hard), create_graph=True)[0]\n",
    "    v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "    v_y = torch.autograd.grad(v_hard, y, grad_outputs=torch.ones_like(v_hard), create_graph=True)[0]\n",
    "    v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "\n",
    "    p_x = torch.autograd.grad(p_hard, x, grad_outputs=torch.ones_like(p_hard), create_graph=True)[0]\n",
    "    p_y = torch.autograd.grad(p_hard, y, grad_outputs=torch.ones_like(p_hard), create_graph=True)[0]\n",
    "\n",
    "    pde_loss_x = u_hard * u_x + v_hard * u_y - nu * (u_xx + u_yy) + (1 / rho) * p_x\n",
    "    pde_loss_y = u_hard * v_x + v_hard * v_y - nu * (v_xx + v_yy) + (1 / rho) * p_y\n",
    "    pde_loss_continuity = u_x + v_y \n",
    "\n",
    "    pde_loss_x = loss_fn(pde_loss_x, torch.zeros_like(pde_loss_x))\n",
    "    pde_loss_y = loss_fn(pde_loss_y, torch.zeros_like(pde_loss_y))\n",
    "    pde_loss_continuity = loss_fn(pde_loss_continuity, torch.zeros_like(pde_loss_continuity))\n",
    "    ####\n",
    "\n",
    "    inlet_condition = (torch.abs(x) < 1e-6)\n",
    "    outlet_condition = (torch.abs(x - ds) < 1e-6)\n",
    "    wall_condition = (distances < 1e-6)\n",
    "\n",
    "    u_avg = nu / d\n",
    "    u_max = (3 / 2) * u_avg\n",
    "    u_inlet = u_max * (1 - (4 * (((ds / 2) - y) ** 2)) / ((ds - d) ** 2))\n",
    "\n",
    "    inlet_loss_u = mse_loss(u_hard[inlet_condition], u_inlet[inlet_condition]) if u_inlet[inlet_condition].numel() > 0 else torch.tensor(0.0, device=device)\n",
    "    inlet_loss_v = mse_loss(v_hard[inlet_condition], torch.zeros_like(v_hard[inlet_condition])) if v_hard[inlet_condition].numel() > 0 else torch.tensor(0.0, device=device)\n",
    "    inlet_loss_p = mse_loss(p_hard[inlet_condition], torch.full_like(p_hard[inlet_condition], dp)) if p_hard[inlet_condition].numel() > 0 else torch.tensor(0.0, device=device)\n",
    "\n",
    "    inlet_loss = inlet_loss_u + inlet_loss_v + inlet_loss_p\n",
    "\n",
    "    outlet_loss_p = mse_loss(p_hard[outlet_condition], torch.zeros_like(p_hard[outlet_condition])) if p_hard[outlet_condition].numel() > 0 else torch.tensor(0.0, device=device)\n",
    "\n",
    "    outlet_loss = outlet_loss_p\n",
    "\n",
    "    wall_loss_u = mse_loss(u_hard[wall_condition], torch.zeros_like(u_hard[wall_condition])) if u_hard[wall_condition].numel() > 0 else torch.tensor(0.0, device=device)\n",
    "    wall_loss_v = mse_loss(v_hard[wall_condition], torch.zeros_like(v_hard[wall_condition])) if v_hard[wall_condition].numel() > 0 else torch.tensor(0.0, device=device)\n",
    "\n",
    "    wall_loss = wall_loss_u + wall_loss_v\n",
    "    \n",
    "    loss_u = loss_fn(u_hard, targets[:, 0])\n",
    "    loss_v = loss_fn(v_hard, targets[:, 1])\n",
    "    loss_p = loss_fn(p_hard, targets[:, 2])\n",
    "\n",
    "    boundaries_weight = 1\n",
    "    pde_weight = 1\n",
    "    data_weight = 0\n",
    "    \n",
    "    total_loss = data_weight * (loss_u + loss_v + loss_p) + boundaries_weight * (inlet_loss + outlet_loss + wall_loss) + pde_weight * (pde_loss_x + pde_loss_y + pde_loss_continuity)\n",
    "\n",
    "    return total_loss, loss_u, loss_v, loss_p,\\\n",
    "        inlet_loss, outlet_loss, wall_loss, \\\n",
    "        pde_loss_x, pde_loss_y, pde_loss_continuity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7ccf6360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_pairs(unique_dn, ds, N):\n",
    "    device = unique_dn.device\n",
    "    K = unique_dn.shape[0]\n",
    "\n",
    "    idx_dn = torch.randint(0, K, (N,), dtype=torch.long, device=device)\n",
    "    dn = unique_dn[idx_dn]\n",
    "    d = dn[:, 0]\n",
    "    n = dn[:, 1]\n",
    "\n",
    "    t = torch.rand(N, device=device)\n",
    "\n",
    "    tilt = ds / n\n",
    "\n",
    "    x_bot = ds * t\n",
    "    y_bot = tilt * t\n",
    "\n",
    "    x_top = ds * t\n",
    "    y_top = ds + tilt * t\n",
    "\n",
    "    bottom_inp = torch.stack([x_bot, y_bot, d, n], dim=1)\n",
    "    top_inp    = torch.stack([x_top, y_top, d, n], dim=1)\n",
    "\n",
    "    return bottom_inp, top_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d0eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset = DLD_Dataset(data_path, data_pattern)\n",
    "    print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(f\"Number of batches: {len(dataloader)}\")\n",
    "\n",
    "    net_u, net_v, net_p, optimizer_u, optimizer_v, optimizer_p, scheduler_u, scheduler_v, scheduler_p = initialize_models()\n",
    "\n",
    "    min_loss = float('inf')\n",
    "\n",
    "    loss_history = {\n",
    "        'epoch': [],\n",
    "        'total_loss': [],\n",
    "        'loss_u': [],\n",
    "        'loss_v': [],\n",
    "        'loss_p': [],\n",
    "        'inlet_loss': [],\n",
    "        'outlet_loss': [],\n",
    "        'wall_loss': [],\n",
    "        'periodic_loss': [],\n",
    "        'pde_loss_x': [],\n",
    "        'pde_loss_y': [],\n",
    "        'pde_loss_continuity': [],\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs+1):\n",
    "        total_loss, total_loss_u, total_loss_v, total_loss_p, \\\n",
    "            total_inlet_loss, total_outlet_loss, total_wall_loss, \\\n",
    "            total_pde_loss_x, total_pde_loss_y, total_pde_loss_continuity = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        \n",
    "        total_periodic_loss = 0.0\n",
    "\n",
    "        for inputs, targets in dataloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer_u.zero_grad()\n",
    "            optimizer_v.zero_grad()\n",
    "            optimizer_p.zero_grad()\n",
    "\n",
    "            loss, loss_u, loss_v, loss_p, \\\n",
    "                inlet_loss, outlet_loss, wall_loss, \\\n",
    "                pde_loss_x, pde_loss_y, pde_loss_continuity = criterion(inputs, targets, net_u, net_v, net_p, loss_fn, epoch, ds=ds, dp=dp)\n",
    "            \n",
    "            bottom_inputs, top_inputs = periodic_pairs(torch.unique(inputs[:, 2:4], dim=0).to(device), ds, 100)\n",
    "            bottom_inputs = bottom_inputs.to(device)\n",
    "            top_inputs = top_inputs.to(device)\n",
    "\n",
    "            periodic_loss = 0.0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                u_bottom = net_u(bottom_inputs).squeeze(1)\n",
    "                v_bottom = net_v(bottom_inputs).squeeze(1)\n",
    "                p_bottom = net_p(bottom_inputs).squeeze(1)\n",
    "\n",
    "                u_top = net_u(top_inputs).squeeze(1)\n",
    "                v_top = net_v(top_inputs).squeeze(1)\n",
    "                p_top = net_p(top_inputs).squeeze(1)\n",
    "\n",
    "                # Periodic boundary condition loss\n",
    "                periodic_loss += mse_loss(u_bottom, u_top)\n",
    "                periodic_loss += mse_loss(v_bottom, v_top)\n",
    "                periodic_loss += mse_loss(p_bottom, p_top)\n",
    "\n",
    "            loss += periodic_loss\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer_u.step()\n",
    "            optimizer_v.step()\n",
    "            optimizer_p.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_loss_u += loss_u.item()\n",
    "            total_loss_v += loss_v.item()\n",
    "            total_loss_p += loss_p.item()\n",
    "\n",
    "            total_inlet_loss += inlet_loss.item()\n",
    "            total_outlet_loss += outlet_loss.item()\n",
    "            total_wall_loss += wall_loss.item()\n",
    "            total_periodic_loss += periodic_loss.item()\n",
    "\n",
    "            total_pde_loss_x += pde_loss_x.item()\n",
    "            total_pde_loss_y += pde_loss_y.item()\n",
    "            total_pde_loss_continuity += pde_loss_continuity.item()\n",
    "\n",
    "        total_loss_u /= len(dataloader)\n",
    "        total_loss_v /= len(dataloader)\n",
    "        total_loss_p /= len(dataloader)\n",
    "        \n",
    "        total_inlet_loss /= len(dataloader)\n",
    "        total_outlet_loss /= len(dataloader)\n",
    "        total_wall_loss /= len(dataloader)\n",
    "        total_periodic_loss /= len(dataloader)\n",
    "\n",
    "        total_pde_loss_x /= len(dataloader)\n",
    "        total_pde_loss_y /= len(dataloader)\n",
    "        total_pde_loss_continuity /= len(dataloader)\n",
    "        total_loss /= len(dataloader)\n",
    "\n",
    "        scheduler_u.step(total_loss_u)\n",
    "        scheduler_v.step(total_loss_v)\n",
    "        scheduler_p.step(total_loss_p)\n",
    "\n",
    "        loss_history['epoch'].append(epoch)\n",
    "        loss_history['total_loss'].append(total_loss)\n",
    "        loss_history['loss_u'].append(total_loss_u)\n",
    "        loss_history['loss_v'].append(total_loss_v)\n",
    "        loss_history['loss_p'].append(total_loss_p)\n",
    "\n",
    "        loss_history['inlet_loss'].append(total_inlet_loss)\n",
    "        loss_history['outlet_loss'].append(total_outlet_loss)\n",
    "        loss_history['wall_loss'].append(total_wall_loss)\n",
    "        loss_history['periodic_loss'].append(periodic_loss.item())\n",
    "\n",
    "        loss_history['pde_loss_x'].append(total_pde_loss_x)\n",
    "        loss_history['pde_loss_y'].append(total_pde_loss_y)\n",
    "        loss_history['pde_loss_continuity'].append(total_pde_loss_continuity)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, Total Loss: {total_loss:.4f} || Loss U: {total_loss_u:.4f}, Loss V: {total_loss_v:.4f}, Loss P: {total_loss_p:.4f} \"\n",
    "            f\"|| Inlet Loss: {total_inlet_loss:.4f}, Outlet Loss: {total_outlet_loss:.4f}, Wall Loss: {total_wall_loss:.4f}, Periodic Loss: {periodic_loss.item():.4f} \"\n",
    "            f\"|| PDE Losses: x: {total_pde_loss_x:.4f}, y: {total_pde_loss_y:.4f}, continuity: {total_pde_loss_continuity:.4f} || Time: {time.time() - start_time:.2f}s\")\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        if total_loss < min_loss:\n",
    "            min_loss = total_loss\n",
    "            torch.save(net_u.state_dict(), f\"{weights_path}/best_u.pth\")\n",
    "            torch.save(net_v.state_dict(), f\"{weights_path}/best_v.pth\")\n",
    "            torch.save(net_p.state_dict(), f\"{weights_path}/best_p.pth\")\n",
    "            print(f\"New best model saved with loss: {min_loss:.4f} at epoch {epoch}\")\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            torch.save(net_u.state_dict(), f\"{weights_path}/epoch_{epoch}_u.pth\")\n",
    "            torch.save(net_v.state_dict(), f\"{weights_path}/epoch_{epoch}_v.pth\")\n",
    "            torch.save(net_p.state_dict(), f\"{weights_path}/epoch_{epoch}_p.pth\")\n",
    "            print(f\"Checkpoint saved at epoch {epoch}\")\n",
    "    \n",
    "    loss_df = pd.DataFrame(loss_history)\n",
    "    loss_df.to_csv(f\"results/loss_history.csv\", index=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(loss_history['epoch'], loss_history['loss_u'], label='Loss U', color='blue')\n",
    "    plt.plot(loss_history['epoch'], loss_history['loss_v'], label='Loss V', color='orange')\n",
    "    plt.plot(loss_history['epoch'], loss_history['loss_p'], label='Loss P', color='green')\n",
    "    plt.plot(loss_history['epoch'], loss_history['total_loss'], label='Total Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss History')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(f\"results/loss_history.png\")\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d1ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 99603\n",
      "Number of batches: 50\n",
      "Epoch 0/500, Total Loss: 0.0708 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0041, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0046 || PDE Losses: x: 0.0624, y: 0.0000, continuity: 0.0001 || Time: 4.49s\n",
      "New best model saved with loss: 0.0708 at epoch 0\n",
      "Checkpoint saved at epoch 0\n",
      "Epoch 1/500, Total Loss: 0.0700 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0041, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0141 || PDE Losses: x: 0.0624, y: 0.0000, continuity: 0.0000 || Time: 4.73s\n",
      "New best model saved with loss: 0.0700 at epoch 1\n",
      "Epoch 2/500, Total Loss: 0.0844 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0042, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0017 || PDE Losses: x: 0.0622, y: 0.0001, continuity: 0.0000 || Time: 4.69s\n",
      "Epoch 3/500, Total Loss: 0.0858 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0041, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0534 || PDE Losses: x: 0.0621, y: 0.0001, continuity: 0.0000 || Time: 4.55s\n",
      "Epoch 4/500, Total Loss: 0.0959 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0041, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0284 || PDE Losses: x: 0.0620, y: 0.0002, continuity: 0.0000 || Time: 4.91s\n",
      "Epoch 5/500, Total Loss: 0.0921 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0041, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0254 || PDE Losses: x: 0.0620, y: 0.0001, continuity: 0.0000 || Time: 4.60s\n",
      "Epoch 6/500, Total Loss: 0.0922 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0040, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0228 || PDE Losses: x: 0.0620, y: 0.0001, continuity: 0.0000 || Time: 4.84s\n",
      "Epoch 7/500, Total Loss: 0.1113 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0042, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0670 || PDE Losses: x: 0.0618, y: 0.0003, continuity: 0.0000 || Time: 4.68s\n",
      "Epoch 8/500, Total Loss: 0.0936 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0040, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0484 || PDE Losses: x: 0.0620, y: 0.0002, continuity: 0.0000 || Time: 4.81s\n",
      "Epoch 9/500, Total Loss: 0.0851 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0040, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0000 || PDE Losses: x: 0.0623, y: 0.0001, continuity: 0.0000 || Time: 4.69s\n",
      "Epoch 10/500, Total Loss: 0.0666 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0040, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0001 || PDE Losses: x: 0.0625, y: 0.0000, continuity: 0.0000 || Time: 4.72s\n",
      "New best model saved with loss: 0.0666 at epoch 10\n",
      "Epoch 11/500, Total Loss: 0.0766 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0041, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0145 || PDE Losses: x: 0.0623, y: 0.0001, continuity: 0.0001 || Time: 4.91s\n",
      "Epoch 12/500, Total Loss: 0.0956 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0040, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0651 || PDE Losses: x: 0.0620, y: 0.0002, continuity: 0.0001 || Time: 4.78s\n",
      "Epoch 13/500, Total Loss: 0.0910 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0041, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0316 || PDE Losses: x: 0.0621, y: 0.0001, continuity: 0.0001 || Time: 4.46s\n",
      "Epoch 14/500, Total Loss: 0.0965 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0042, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0387 || PDE Losses: x: 0.0620, y: 0.0002, continuity: 0.0000 || Time: 4.85s\n",
      "Epoch 15/500, Total Loss: 0.0974 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0040, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.1043 || PDE Losses: x: 0.0620, y: 0.0002, continuity: 0.0000 || Time: 4.72s\n",
      "Epoch 16/500, Total Loss: 0.0990 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0038, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0002 || PDE Losses: x: 0.0623, y: 0.0002, continuity: 0.0001 || Time: 4.90s\n",
      "Epoch 17/500, Total Loss: 0.0665 || Loss U: 0.0205, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0037, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0003 || PDE Losses: x: 0.0625, y: 0.0000, continuity: 0.0001 || Time: 4.78s\n",
      "New best model saved with loss: 0.0665 at epoch 17\n",
      "Epoch 18/500, Total Loss: 0.0684 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0037, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0097 || PDE Losses: x: 0.0624, y: 0.0000, continuity: 0.0001 || Time: 4.80s\n",
      "Epoch 19/500, Total Loss: 0.0724 || Loss U: 0.0205, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0039, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0152 || PDE Losses: x: 0.0623, y: 0.0000, continuity: 0.0001 || Time: 4.84s\n",
      "Epoch 20/500, Total Loss: 0.0863 || Loss U: 0.0205, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0039, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0202 || PDE Losses: x: 0.0619, y: 0.0001, continuity: 0.0002 || Time: 4.81s\n",
      "Epoch 21/500, Total Loss: 0.0845 || Loss U: 0.0205, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0040, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0341 || PDE Losses: x: 0.0619, y: 0.0001, continuity: 0.0002 || Time: 4.80s\n",
      "Epoch 22/500, Total Loss: 0.0979 || Loss U: 0.0206, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0040, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0099 || PDE Losses: x: 0.0619, y: 0.0002, continuity: 0.0000 || Time: 4.60s\n",
      "Epoch 23/500, Total Loss: 0.0860 || Loss U: 0.0205, Loss V: 0.0005, Loss P: 0.0012 || Inlet Loss: 0.0038, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.0157 || PDE Losses: x: 0.0621, y: 0.0001, continuity: 0.0001 || Time: 4.06s\n",
      "Epoch 24/500, Total Loss: 0.1207 || Loss U: 0.0205, Loss V: 0.0005, Loss P: 0.0011 || Inlet Loss: 0.0039, Outlet Loss: 0.0000, Wall Loss: 0.0000, Periodic Loss: 0.1144 || PDE Losses: x: 0.0615, y: 0.0003, continuity: 0.0001 || Time: 5.07s\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
