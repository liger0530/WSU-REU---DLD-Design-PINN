{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "988c3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "from scipy.interpolate import griddata\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.functional import mse_loss\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f28dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(x, y, d, n):\n",
    "    \"\"\"Compute the minimum distance of (x, y) from the nearest circular post.\"\"\"\n",
    "    tilt = 0.4/n\n",
    "    centers = [(0, 0), (0, 0.4), (0.4, tilt), (0.4, 0.4+tilt)]\n",
    "    \n",
    "    distances = torch.full_like(x, float(\"inf\"))  # Initialize distances with large values\n",
    "\n",
    "    for cx, cy in centers:\n",
    "        r = d / 2\n",
    "        distance_to_post = torch.sqrt((x - cx) ** 2 + (y - cy) ** 2) - r\n",
    "        distances = torch.minimum(distances, distance_to_post)  # Take the minimum distance\n",
    "\n",
    "    return torch.maximum(distances, torch.tensor(0.0))  # Set negative distances to zero\n",
    "\n",
    "def smooth_distance_to_posts(x, y, d, n, alpha=128.0, beta=50.0):\n",
    "    \"\"\"\n",
    "    Smooth, differentiable approximation to the clamped min distance to 4 circular posts.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y, d, n : [N,1] tensors (requires_grad OK)\n",
    "        n is used to compute tilt = 0.4 / n.\n",
    "    alpha : float\n",
    "        Softmin sharpness. Larger -> closer to true min. Try 32–128.\n",
    "    beta : float\n",
    "        Softplus sharpness. Larger -> closer to ReLU. Try 10–50.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dist_mask : [N,1] tensor >= 0\n",
    "        Smoothly zero inside posts; smoothly ramps outside.\n",
    "    \"\"\"\n",
    "    tilt = 0.4 / n  # [N,1]\n",
    "\n",
    "    # Centers, broadcast to [N,4]\n",
    "    cx = torch.cat([\n",
    "        torch.zeros_like(x),            # x=0  (post 1)\n",
    "        torch.zeros_like(x),            # x=0  (post 2)\n",
    "        torch.full_like(x, 0.4),        # x=0.4(post 3)\n",
    "        torch.full_like(x, 0.4)         # x=0.4(post 4)\n",
    "    ], dim=1)\n",
    "\n",
    "    cy = torch.cat([\n",
    "        torch.zeros_like(y),            # y=0\n",
    "        torch.full_like(y, 0.4),        # y=0.4\n",
    "        tilt,                           # y=tilt\n",
    "        0.4 + tilt                      # y=0.4+tilt\n",
    "    ], dim=1)\n",
    "\n",
    "    r = (d / 2).expand_as(cx)           # [N,4]\n",
    "\n",
    "    # Signed distance to each post (neg inside)\n",
    "    dist_each = torch.sqrt((x - cx)**2 + (y - cy)**2 + 1e-12) - r  # [N,4]\n",
    "\n",
    "    # Softmin across posts\n",
    "    # scale inputs to control sharpness; detach to avoid overflow hazard\n",
    "    dist_softmin = -torch.logsumexp(-alpha * dist_each, dim=1, keepdim=True) / alpha  # [N,1]\n",
    "\n",
    "    # Smooth clamp >=0\n",
    "    dist_mask = F.softplus(dist_softmin, beta=beta)  # ~ReLU(dist_softmin)\n",
    "\n",
    "    return dist_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf984315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path containing CSV files\n",
    "folder_path = \"data/csv\"\n",
    "\n",
    "# Define value ranges\n",
    "first_values = np.arange(0.3, 0.7, 0.05)  # 0.25 to 0.7 with step 0.05\n",
    "# second_values = np.arange(3, 15, 1)  # 3 to 14\n",
    "second_values = [10]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27904e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing W_0.3_10_1.csv...\n",
      "Saved distances plot for W_0.3_10_1.csv\n",
      "Processing W_0.35_10_1.csv...\n",
      "Saved distances plot for W_0.35_10_1.csv\n",
      "Processing W_0.4_10_1.csv...\n",
      "Saved distances plot for W_0.4_10_1.csv\n",
      "Processing W_0.45_10_1.csv...\n",
      "Saved distances plot for W_0.45_10_1.csv\n",
      "Processing W_0.5_10_1.csv...\n",
      "Saved distances plot for W_0.5_10_1.csv\n",
      "Processing W_0.55_10_1.csv...\n",
      "Saved distances plot for W_0.55_10_1.csv\n",
      "Processing W_0.6_10_1.csv...\n",
      "Saved distances plot for W_0.6_10_1.csv\n",
      "Processing W_0.65_10_1.csv...\n",
      "Saved distances plot for W_0.65_10_1.csv\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all possible files\n",
    "for first in first_values:\n",
    "    for second in second_values:\n",
    "        first_str = f\"{first:.2f}\".rstrip(\"0\").rstrip(\".\")\n",
    "        file_name = f\"W_{first_str}_{second}_1.csv\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"Processing {file_name}...\")\n",
    "            \n",
    "            # Load CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Extract input and output data\n",
    "            input_data = df.iloc[:, [0, 1, 5, 7]].values  # (x, y, d, N) [0, 1, 5, 7]\n",
    "            output_data = df.iloc[:, [2, 3, 4]].values  # (u, v, p)\n",
    "            \n",
    "            x = torch.tensor(input_data[:, 0], dtype=torch.float32, device=device).view(-1, 1)\n",
    "            y = torch.tensor(input_data[:, 1], dtype=torch.float32, device=device).view(-1, 1)\n",
    "            d = torch.tensor(input_data[:, 2], dtype=torch.float32, device=device).view(-1, 1)\n",
    "\n",
    "            # n = input_tensor[:, 3]\n",
    "            n = torch.full_like(x, 10)  # Assuming n is constant for this example\n",
    "            \n",
    "            # Compute distance\n",
    "            distances_1 = compute_distance(x, y, d, n)\n",
    "            distances_2 = smooth_distance_to_posts(x, y, d, n)\n",
    "\n",
    "            x_np = x.cpu().numpy().ravel()\n",
    "            y_np = y.cpu().numpy().ravel()\n",
    "            d1_np = distances_1.cpu().numpy().ravel()\n",
    "            d2_np = distances_2.cpu().numpy().ravel()\n",
    "\n",
    "            # plot the distances\n",
    "            vmax = max(d1_np.max(), d2_np.max())\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.scatter(x_np, y_np, c=d1_np, cmap='viridis', s=1, vmin=0, vmax=vmax)\n",
    "            plt.colorbar(label='Distance')\n",
    "            plt.title('Distance to Posts (compute_distance)')\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('y')\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.scatter(x_np, y_np, c=d2_np, cmap='viridis', s=1, vmin=0, vmax=vmax)\n",
    "            plt.colorbar(label='Distance')\n",
    "            plt.title('Distance to Posts (smooth_distance_to_posts)')\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('y')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f\"distances_{first_str}_{second}.png\")\n",
    "            plt.close()\n",
    "            print(f\"Saved distances plot for {file_name}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
